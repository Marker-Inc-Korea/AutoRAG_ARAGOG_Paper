node_lines:
- node_line_name: pre_retrieve_node_line  # Arbitrary node line name
  nodes:
    - node_type: query_expansion
      strategy:
        metrics: [ragas_context_precision]
        speed_threshold: 10
        top_k: 10
        retrieval_modules:
          - module_type: bm25
            bm25_tokenizer: [gpt2]
      modules:
        - module_type: pass_query_expansion
        - module_type: query_decompose
          llm: openai
          temperature: [0.2, 1.0]
        - module_type: hyde
          llm: openai
          max_token: 64
- node_line_name: retrieve_node_line  # Arbitrary node line name
  nodes:
    - node_type: retrieval
      strategy:
        metrics: [ragas_context_precision]
        speed_threshold: 10
      top_k: 10
      modules:
        - module_type: bm25
          bm25_tokenizer: [gpt2]
        - module_type: vectordb
          embedding_model: openai_embed_3_large
        - module_type: hybrid_rrf
          target_modules: ('bm25', 'vectordb')
          rrf_k: [3, 5, 10]
        - module_type: hybrid_cc
          target_modules: ('bm25', 'vectordb')
          weights:
            - (0.7, 0.3)
        - module_type: hybrid_rsf
          target_modules: ('bm25', 'vectordb')
          weights:
            - (0.7, 0.3)
        - module_type: hybrid_dbsf
          target_modules: ('bm25', 'vectordb')
          weights:
            - (0.7, 0.3)
    - node_type: passage_augmenter
      strategy:
        metrics: [ragas_context_precision]
        speed_threshold: 5
      top_k: 15
      embedding_model: openai
      modules:
        - module_type: pass_passage_augmenter
        - module_type: prev_next_augmenter
          mode: both
    - node_type: passage_reranker
      strategy:
        metrics: [ragas_context_precision]
        speed_threshold: 10
      top_k: 5
      modules:
        - module_type: pass_reranker
        - module_type: tart
        - module_type: monot5
        - module_type: upr
        - module_type: rankgpt
        - module_type: colbert_reranker
        - module_type: sentence_transformer_reranker
        - module_type: flag_embedding_reranker
        - module_type: flag_embedding_llm_reranker
    - node_type: passage_compressor
      strategy:
        metrics: [retrieval_token_f1, retrieval_token_recall, retrieval_token_precision]
        speed_threshold: 10
      modules:
        - module_type: pass_compressor
        - module_type: tree_summarize
          llm: openai
          model: gpt-3.5-turbo-16k
        - module_type: refine
          llm: openai
          model: gpt-3.5-turbo-16k
- node_line_name: post_retrieve_node_line  # Arbitrary node line name
  nodes:
    - node_type: prompt_maker
      strategy:
        metrics:
          - metric_name: meteor
          - metric_name: rouge
          - metric_name: sem_score
            embedding_model: openai
          - metric_name: g_eval
        speed_threshold: 10
        generator_modules:
          - module_type: llama_index_llm
            llm: openai
            model: [ gpt-3.5-turbo ]
            temperature: [ 0.0 ]
      modules:
        - module_type: fstring
          prompt:
            - |
              You are an expert Q&A system that is trusted around the world for your factual accuracy.
              Always answer the query using the provided context information, and not prior knowledge. Ensure your answers are fact-based and accurately reflect the context provided.
              Some rules to follow:
              1. Never directly reference the given context in your answer.
              2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.
              3. Focus on succinct answers that provide only the facts necessary, do not be verbose.Your answers should be max two sentences, up to 250 characters.
              ---------------------
              {retrieved_contents}
              ---------------------
              Given the context information and not prior knowledge, answer the query.
              Query: {query}
              Answer:
        - module_type: long_context_reorder
          prompt:
            - |
              You are an expert Q&A system that is trusted around the world for your factual accuracy.
              Always answer the query using the provided context information, and not prior knowledge. Ensure your answers are fact-based and accurately reflect the context provided.
              Some rules to follow:
              1. Never directly reference the given context in your answer.
              2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.
              3. Focus on succinct answers that provide only the facts necessary, do not be verbose.Your answers should be max two sentences, up to 250 characters.
              ---------------------
              {retrieved_contents}
              ---------------------
              Given the context information and not prior knowledge, answer the query.
              Query: {query}
              Answer:
    - node_type: generator
      strategy:
        metrics:
          - metric_name: meteor
          - metric_name: rouge
          - metric_name: sem_score
            embedding_model: openai
          - metric_name: g_eval
        speed_threshold: 10
      modules:
        - module_type: llama_index_llm
          llm: [openai]
          model: [gpt-3.5-turbo]
          temperature: [0.0]
